# change from o4
model:
  target: sound_synthesis2.modeling.dalle_wav.DALLE
  params:
    content_info: {key: audio}
    condition_info: {key: text}
    n_q: 3  # the encodec codebook's number
    diffusion_config:      
        target: sound_synthesis2.modeling.transformers.diffusion_transformer_wav_v2_share.DiffusionTransformer
        params:
          diffusion_step: 100
          n_q: 3
          alpha_init_type: 'alpha1'       # init_type = fix or cos or linear 
          auxiliary_loss_weight: 5.0e-4
          adaptive_auxiliary_loss: True
          mask_weight: [1, 1]    # the loss weight on mask region and non-mask region

          transformer_config:
            target: sound_synthesis2.modeling.transformers.transformer_utils_wav_unet_share_3code.Text2ImageTransformer
            params:
              attn_type: 'selfcross' # using self attention
              n_q: 3
              n_layer: 16 # we may use large model
              n_embd: 512 # the dim of embedding dims
              condition_dim: 512
              n_head: 8 
              attn_pdrop: 0.0
              resid_pdrop: 0.0
              block_activate: GELU2
              timestep_type: 'adalayernorm'    # adainsnorm or adalayernorm and abs
              mlp_hidden_times: 4
              
              content_emb_config:
                target: sound_synthesis2.modeling.embeddings.dalle_mask_wav_embedding1d_3code.DalleMaskImageEmbedding
                params:
                  num_embed: 1026    #should be quantize_number
                  max_size: 16000
                  n_q: 3
                  embed_dim: 512 # the dim of postion embedding
                  trainable: True
                  pos_emb_type: embedding  

solver:
  base_lr: 3.0e-6
  adjust_lr: none # not adjust lr according to total batch_size
  max_epochs: 400
  save_epochs: 1
  validation_epochs: 400
  sample_iterations: epoch  # epoch #30000      # how many iterations to perform sampling once ?
  print_specific_things: True
  sr: 24000

  ema:
    decay: 0.99
    update_interval: 25
    device: cpu

  clip_grad_norm:
    target: sound_synthesis2.engine.clip_grad_norm.ClipGradNorm
    params:
      start_iteration: 0
      end_iteration: 5000
      max_norm: 0.5
  optimizers_and_schedulers: # a list of configures, so we can config several optimizers and schedulers
  - name: none # default is None
    optimizer:
      target: torch.optim.AdamW
      params: 
        betas: !!python/tuple [0.9, 0.96]
        weight_decay: 4.5e-2
    scheduler:
      step_iteration: 1
      target: sound_synthesis2.engine.lr_scheduler.ReduceLROnPlateauWithWarmup
      params:
        factor: 0.5
        patience: 25000
        min_lr: 1.0e-6
        threshold: 1.0e-1
        threshold_mode: rel
        warmup_lr: 4.5e-4 # the lr to be touched after warmup
        warmup: 1000 

dataloader:
  batch_size: 1 # 16
  num_workers: 0
  train_datasets: # a list of configures, so we can combine several schedulers
    - target: sound_synthesis2.data.semantic_dataset.SemanticDataset
      params:
        folder: LibriTTS_1000 # your folder
        num_quant: 3
        stage: train
  
  validation_datasets:
    - target: sound_synthesis2.data.semantic_dataset.SemanticDataset
      params:
        folder: LibriTTS_1000 # your folder
        stage: test
        num_quant: 3
        